{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e1d040",
   "metadata": {},
   "source": [
    "Roger Cloud\n",
    "\n",
    "## Abstract\n",
    "*A single vector number system for all hyperoperations*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae1381",
   "metadata": {},
   "source": [
    "Let's pretend $a  = -2$ and $b = 3$ to substitute in as real number examples for our algebraic abstractions.\n",
    "\n",
    "Why am I using $-2$ and $3$? Well, I am using a positive number for $b$ because I am demonstrating an example in which our vector approaches $+ \\infty$, not $- \\infty$, but both work. I am using a negative number for $a$ because the opposite signage between $a$ and $b$ will show the contrast in the properties of this number system compared to the normal two vector number system, at least beginning with the multiplication hyperoperation.\n",
    "\n",
    "If we iterate through the hyperoperations, we will see:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15c795",
   "metadata": {},
   "source": [
    "### **hyper0 (zeration)**: $a + 1$\n",
    "\n",
    "Now, if we substitute with our pretend value(s), we will see: $-2 + 1 = -1$\n",
    "\n",
    "We see that $-1 > -2$ ...our number changes in the direction of $+ \\infty$\n",
    "\n",
    "With zeration, no matter which positive real number you substitute in for $b$, our *directional change* will be the same! ($b$ is not even a part of the equation, so I would sure hope so!)\n",
    "\n",
    "Therefore, zeration already exists on a single vector number system!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2748d",
   "metadata": {},
   "source": [
    "### **hyper1 (addition)**: $a + b$\n",
    "\n",
    "Now, if we substitute with our pretend value(s), we will see: $-2 + 3 = 1$\n",
    "\n",
    "We see that $1 > -2$ ...our number changes in the direction of $+ \\infty$\n",
    "\n",
    "With addition, it is *also true* that no matter which positive real number we substitute in for $b$, our *directional change* will be the same!\n",
    "\n",
    "Therefore, addition *also* already exists on a single vector number system!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091e5e7",
   "metadata": {},
   "source": [
    "### **hyper2 (multiplication)**: $a * b$\n",
    "\n",
    "***So here's where the single vector number system forks from the two vector number system.***\n",
    "\n",
    "So first, let's go through the example using the traditional two vector number system. \n",
    "\n",
    "If we substitute with our pretend value(s), we will see: $-2 * 3 = -6$\n",
    "\n",
    "So with the traditional two vector number system, this is where our observation deviates from hyper0 and hyper1.\n",
    "We see that $-6$ **<** $-2$ ...so our $b$ was a positive number, but our value changed in the direction of $- \\infty$ this time.\n",
    "\n",
    "***So if instead, we continued with a single vector number system on hyper2 (multiplication), what would this look like?***\n",
    "\n",
    "So back to the example, if we substitute our pretend values(s), so will have: $-2 * 3 = 4$\n",
    "\n",
    "Our traditional two vector system interprets this as: $-2 + -2 + -2 = -6$\n",
    "For a one vector system, this would be interpreted as: $-2 + 2 + 2 + 2 = 4$\n",
    "\n",
    "In words, the *traditional two vector system* says **We are going to add a series of three negative twos together**\n",
    "\n",
    "In words, the *single vector system* says **We are going to add a series of three twos to negative two**\n",
    "\n",
    "The key difference with single vector multiplication, is that whether our $a$ value is positive or negative, *multiplying* it will cause a directional change towards $+ \\infty$, hence ***single vector***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b1f16",
   "metadata": {},
   "source": [
    "### **hyper3 (exponentiation)**: $a^b$\n",
    "\n",
    "***So our fork happens at the multiplication hyperoperation. I am demonstrating the exponentiation hyperoperation for continuation purposes, but the operations shown here are using the same abstract alteration introduced in hyper2.***\n",
    "\n",
    "So we can go through an example using both traditional two vector exponentiation and single vector exponentiation; starting with traditional.\n",
    "\n",
    "With traditional, if we substitute in our pretend value(s), we will see: $-2^3 = -8$\n",
    "\n",
    "The traditional language interpretation would be: ***We are going to multiply a series of negative twos together***\n",
    "\n",
    "With single vector, if we substitute in our pretend values(s), we will see: $-2^3 = 6$\n",
    "\n",
    "The single vector language interpretation would be: ***We are going to multiply a series of three twos together and add that to negative two***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa227d7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc67d1f",
   "metadata": {},
   "source": [
    "### Applied example for preferential use of single vector system over two vector system\n",
    "\n",
    "***The standard deviation, or, the meaning that the standard deviation actually intends to measure***\n",
    "\n",
    "The standard deviation attempts to communicate a normalized measure for the level of dispersion of an array of numbers\n",
    "\n",
    "The problem with finding the standard deviation of a sample is that by definition, there will always be at least one value in the sample that are both greater than, and less than, the mean.\n",
    "\n",
    "So, when you are trying to come up with a measure for the dispersion, the equation you use to represent this must be cognizant of this truth. The current approach to attempt to solve this problem is to *square* each of the differences from the value to the mean and sum these squared differences, such that the signage becomes uniform. This solves the signage problem, but in my opinion creates a different problem wherein it increases the weights of increasingly greater residuals. I am intuitively led to believe that actually the relative inverse of this should be going on; increasingly small residuals should receive greater adjusted weights and increasingly large residuals should receive lower adjusted weights (so perhaps the sum of the logarithm of each absolute residual). But I (partially) digress...\n",
    "\n",
    "The application of a single vector system to this inherent problem in the dispersion equation is that negative numbers will face the same direction as positive numbers, so we can therefore perform signage agnostic operations.\n",
    "\n",
    "Take the list of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03560db",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlistone = [2, 8, 3, 4, 9, 10, 5, 15]\n",
    "numlisttwo = [x / 100 for x in numlistone]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbcea6",
   "metadata": {},
   "source": [
    "What is the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6fa9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean one 7.0\n",
      "mean two 0.07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "meanone = np.mean(numlistone)\n",
    "meantwo = np.mean(numlisttwo)\n",
    "print('mean one', meanone)\n",
    "print('mean two', meantwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4b26c",
   "metadata": {},
   "source": [
    "Now we want to figure out how disperse the dataset is.\n",
    "\n",
    "So using traditional two vector operations, we can't just take the sum of the differences between each number and the mean because we will end up with..well..$0$, every single time..because of the signage problem.\n",
    "\n",
    "However!\n",
    "\n",
    "Using single vector operations, you very well can do this to obtain a measure of dispersion about the data by simply ***multiplying*** the residuals together, using the method of multiplication formerly introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfad5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.0, 1.0, -4.0, -3.0, 2.0, 3.0, -2.0, 8.0]\n",
      "[-0.05, 0.009999999999999995, -0.04000000000000001, -0.030000000000000006, 0.01999999999999999, 0.03, -0.020000000000000004, 0.07999999999999999]\n"
     ]
    }
   ],
   "source": [
    "residualsone = []\n",
    "residualstwo = []\n",
    "\n",
    "for i in range(len(numlistone)):\n",
    "    residualsone.append(numlistone[i] - meanone)\n",
    "    residualstwo.append(numlisttwo[i] - meantwo)\n",
    "\n",
    "#residuals list\n",
    "print(residualsone)\n",
    "print(residualstwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78031546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Standard Deviation of first set of values: 6480.0\n",
      "Real Standard Deviation of second set of values: -0.052290352929023995\n"
     ]
    }
   ],
   "source": [
    "zeroth_un = residualsone[0]\n",
    "zeroth_do = residualstwo[0]\n",
    "\n",
    "\n",
    "sdone = zeroth_un\n",
    "for i in residualsone[1:]:\n",
    "    sdone = sdone + (i*sdone)\n",
    "    \n",
    "sdtwo = zeroth_do\n",
    "for i in residualstwo[1:]:\n",
    "    sdtwo = sdtwo + (i*sdtwo)\n",
    "    \n",
    "print('Real Standard Deviation of first set of values:', sdone)\n",
    "print('Real Standard Deviation of second set of values:', sdtwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f7a61",
   "metadata": {},
   "source": [
    "There it is. You can now have negative standard deviations around the base you are using. In this case, decimal, so $10$. This shares similar properties with the idea that $if x^y < 1$ $then$ $y < 0$\n",
    "\n",
    "So the idea is that these measures for standard deviation can be applied to any sample with a completely unknown distribution in an unbiased way and without a need for normalization!\n Also.. with this we can now use integers for everything! - Because our $0$ constant sort of acts **as** the decimal point. Though you'll notice this notebook printed out numbers *with* decimal points. This is because of the assumptions of the code running underneath this code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
